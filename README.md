# rag-fastapi-chatbot

ğŸ“„ Document-Based Chatbot using RAG (FastAPI + FAISS)
A Retrieval-Augmented Generation (RAG) based document chatbot built using FastAPI, FAISS, and local embedding models.
This application allows users to upload PDF documents and ask natural language questions, with answers generated from document content.


âœ… Note: Embeddings are generated locally (no paid GenAI embedding APIs used).

ğŸš€ Features
ğŸ“„ Upload PDF documents
âœ‚ï¸ Text chunking for large documents
ğŸ” Vector search using FAISS
ğŸ§  Local embedding generation (free & offline)
ğŸ¤– LLM-based answer generation
âš¡ FastAPI backend
ğŸ“˜ Interactive Swagger UI
ğŸ—ï¸ Tech Stack

Backend: FastAPI
Vector Store: FAISS
Embeddings: Local embedding model (SentenceTransformers)
LLM: Gemini / any compatible LLM
PDF Processing: pdfplumber
Language: Python 3.11+


ğŸ§  How RAG Works (Local Embeddings)
PDF is uploaded
Text is extracted
Text is split into chunks
Embeddings are generated locally
Stored in FAISS vector index
User query is embedded locally
Relevant chunks retrieved
LLM generates final answer using retrieved context

ğŸ’¡ Why Local Embeddings?
âœ… Free (no API cost)
âœ… No rate limits
âœ… Privacy-friendly
âœ… Suitable for production
âœ… Faster local development

ğŸ›¡ï¸ Security Notes
.env is ignored in Git
Uploaded files are not committed
FAISS index files are ignored
No paid embedding APIs used

ğŸ“ˆ Future Enhancements
Multi-document chat
Persistent FAISS storage
Chat memory
Authentication
UI frontend
Streaming responses

ğŸ§‘â€ğŸ’» Author
Sangi
Software Developer | FastAPI | RAG | FAISS | Generative AI

â­ Support
If you find this project useful:
â­ Star the repo
ğŸ´ Fork it
ğŸ’¼ Use it for learning & interviews